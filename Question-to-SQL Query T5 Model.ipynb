{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation of Natural Language Questions to SQL Queries within the Healthcare Domain Using the T5 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track of GPU Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:27.429205Z",
     "iopub.status.busy": "2021-09-19T16:11:27.428599Z",
     "iopub.status.idle": "2021-09-19T16:11:28.296513Z",
     "shell.execute_reply": "2021-09-19T16:11:28.295163Z",
     "shell.execute_reply.started": "2021-09-19T16:11:27.429063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 19 16:11:28 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:28.299139Z",
     "iopub.status.busy": "2021-09-19T16:11:28.298748Z",
     "iopub.status.idle": "2021-09-19T16:11:28.307264Z",
     "shell.execute_reply": "2021-09-19T16:11:28.305604Z",
     "shell.execute_reply.started": "2021-09-19T16:11:28.299103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import essential libraries for data preparation\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:28.310990Z",
     "iopub.status.busy": "2021-09-19T16:11:28.310444Z",
     "iopub.status.idle": "2021-09-19T16:11:28.673608Z",
     "shell.execute_reply": "2021-09-19T16:11:28.672492Z",
     "shell.execute_reply.started": "2021-09-19T16:11:28.310958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the training data to get insight\n",
    "\n",
    "with open(\"../input/train-data/train.json\") as folder:\n",
    "    train_data = json.loads(\"[\" + \n",
    "        folder.read().replace(\"}\\n{\", \"},\\n{\") + \n",
    "    \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:28.676291Z",
     "iopub.status.busy": "2021-09-19T16:11:28.675766Z",
     "iopub.status.idle": "2021-09-19T16:11:28.686913Z",
     "shell.execute_reply": "2021-09-19T16:11:28.685415Z",
     "shell.execute_reply.started": "2021-09-19T16:11:28.676250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:28.689748Z",
     "iopub.status.busy": "2021-09-19T16:11:28.689211Z",
     "iopub.status.idle": "2021-09-19T16:11:28.699695Z",
     "shell.execute_reply": "2021-09-19T16:11:28.698065Z",
     "shell.execute_reply.started": "2021-09-19T16:11:28.689705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['key', 'format', 'question_refine', 'sql', 'question_refine_tok', 'sql_tok'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:28.702679Z",
     "iopub.status.busy": "2021-09-19T16:11:28.701840Z",
     "iopub.status.idle": "2021-09-19T16:11:28.714293Z",
     "shell.execute_reply": "2021-09-19T16:11:28.712496Z",
     "shell.execute_reply.started": "2021-09-19T16:11:28.702631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key': '1f4675717f61aa61ed79e4b4deb69e76',\n",
       " 'format': {'table': [0],\n",
       "  'cond': [[0, 7, 0, 'HAIT']],\n",
       "  'agg_col': [[0, 0]],\n",
       "  'sel': 1},\n",
       " 'question_refine': 'find the number of patients who prefer haitian language.',\n",
       " 'sql': 'SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"LANGUAGE\" = \"HAIT\"',\n",
       " 'question_refine_tok': ['find',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'patients',\n",
       "  'who',\n",
       "  'prefer',\n",
       "  'haitian',\n",
       "  'language',\n",
       "  '.'],\n",
       " 'sql_tok': ['SELECT',\n",
       "  'COUNT',\n",
       "  '(',\n",
       "  'DISTINCT',\n",
       "  'DEMOGRAPHIC.\"SUBJECT_ID\"',\n",
       "  ')',\n",
       "  'FROM',\n",
       "  'DEMOGRAPHIC',\n",
       "  'WHERE',\n",
       "  'DEMOGRAPHIC.\"LANGUAGE\"',\n",
       "  '=',\n",
       "  '\"HAIT\"']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:28.717384Z",
     "iopub.status.busy": "2021-09-19T16:11:28.716860Z",
     "iopub.status.idle": "2021-09-19T16:11:28.725909Z",
     "shell.execute_reply": "2021-09-19T16:11:28.724321Z",
     "shell.execute_reply.started": "2021-09-19T16:11:28.717340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'find the number of patients who prefer haitian language.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][\"question_refine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:28.729101Z",
     "iopub.status.busy": "2021-09-19T16:11:28.728094Z",
     "iopub.status.idle": "2021-09-19T16:11:28.738626Z",
     "shell.execute_reply": "2021-09-19T16:11:28.737053Z",
     "shell.execute_reply.started": "2021-09-19T16:11:28.729055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"LANGUAGE\" = \"HAIT\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][\"sql\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:28.744101Z",
     "iopub.status.busy": "2021-09-19T16:11:28.743787Z",
     "iopub.status.idle": "2021-09-19T16:11:28.751164Z",
     "shell.execute_reply": "2021-09-19T16:11:28.749625Z",
     "shell.execute_reply.started": "2021-09-19T16:11:28.744072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract questions and sql queries, returns pandas dataframe\n",
    "\n",
    "def extract_questions_and_sql(path):\n",
    "    with open(path) as folder:\n",
    "        sql_question_data = json.loads(\"[\" + \n",
    "            folder.read().replace(\"}\\n{\", \"},\\n{\") + \n",
    "        \"]\")\n",
    "    \n",
    "    data_rows = []\n",
    "    \n",
    "    for question_and_sql in sql_question_data:\n",
    "        question = question_and_sql[\"question_refine\"]\n",
    "        sql_query = question_and_sql[\"sql\"]\n",
    "        \n",
    "        data_rows.append({\n",
    "            \"question\": question,\n",
    "            \"sql_query\": sql_query\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:28.755028Z",
     "iopub.status.busy": "2021-09-19T16:11:28.754272Z",
     "iopub.status.idle": "2021-09-19T16:11:29.054069Z",
     "shell.execute_reply": "2021-09-19T16:11:29.052897Z",
     "shell.execute_reply.started": "2021-09-19T16:11:28.754970Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the training data using the extract_questions_and_sql function\n",
    "train_df = extract_questions_and_sql(\"../input/train-data/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.056229Z",
     "iopub.status.busy": "2021-09-19T16:11:29.055838Z",
     "iopub.status.idle": "2021-09-19T16:11:29.081530Z",
     "shell.execute_reply": "2021-09-19T16:11:29.080588Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.056189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>sql_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>find the number of patients who prefer haitian...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>give me the number of patients whose religion ...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count the number of patients whose ethnicity i...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how many patients are diagnosed with the prima...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What number of patients were primarily diagnos...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  find the number of patients who prefer haitian...   \n",
       "1  give me the number of patients whose religion ...   \n",
       "2  count the number of patients whose ethnicity i...   \n",
       "3  how many patients are diagnosed with the prima...   \n",
       "4  What number of patients were primarily diagnos...   \n",
       "\n",
       "                                           sql_query  \n",
       "0  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "1  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "2  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "3  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "4  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 5 rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.083425Z",
     "iopub.status.busy": "2021-09-19T16:11:29.082996Z",
     "iopub.status.idle": "2021-09-19T16:11:29.091088Z",
     "shell.execute_reply": "2021-09-19T16:11:29.089394Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.083385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the total number of rows and columns\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.093596Z",
     "iopub.status.busy": "2021-09-19T16:11:29.092993Z",
     "iopub.status.idle": "2021-09-19T16:11:29.108719Z",
     "shell.execute_reply": "2021-09-19T16:11:29.107251Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.093529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question     0\n",
       "sql_query    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any missing values\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.111096Z",
     "iopub.status.busy": "2021-09-19T16:11:29.110600Z",
     "iopub.status.idle": "2021-09-19T16:11:29.137195Z",
     "shell.execute_reply": "2021-09-19T16:11:29.135644Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.111054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the total number of duplicated rows\n",
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.139374Z",
     "iopub.status.busy": "2021-09-19T16:11:29.138912Z",
     "iopub.status.idle": "2021-09-19T16:11:29.153091Z",
     "shell.execute_reply": "2021-09-19T16:11:29.151299Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.139331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7998"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the total number of unique questions\n",
    "len(train_df.question.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.155611Z",
     "iopub.status.busy": "2021-09-19T16:11:29.155102Z",
     "iopub.status.idle": "2021-09-19T16:11:29.171107Z",
     "shell.execute_reply": "2021-09-19T16:11:29.169712Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.155545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the total number of unique SQL queries\n",
    "len(train_df.sql_query.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.173444Z",
     "iopub.status.busy": "2021-09-19T16:11:29.172693Z",
     "iopub.status.idle": "2021-09-19T16:11:29.190259Z",
     "shell.execute_reply": "2021-09-19T16:11:29.188389Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.173396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>sql_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>count the number of patients who have stayed i...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>count the number of patients who have stayed i...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7311</th>\n",
       "      <td>specify icd9 code for patient id 6983</td>\n",
       "      <td>SELECT DIAGNOSES.\"SHORT_TITLE\" FROM DIAGNOSES ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7315</th>\n",
       "      <td>specify icd9 code for patient id 6983</td>\n",
       "      <td>SELECT PROCEDURES.\"LONG_TITLE\" FROM PROCEDURES...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "2587  count the number of patients who have stayed i...   \n",
       "4755  count the number of patients who have stayed i...   \n",
       "7311              specify icd9 code for patient id 6983   \n",
       "7315              specify icd9 code for patient id 6983   \n",
       "\n",
       "                                              sql_query  \n",
       "2587  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "4755  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "7311  SELECT DIAGNOSES.\"SHORT_TITLE\" FROM DIAGNOSES ...  \n",
       "7315  SELECT PROCEDURES.\"LONG_TITLE\" FROM PROCEDURES...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the rows of the duplicated questions\n",
    "train_df[train_df.question.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.193347Z",
     "iopub.status.busy": "2021-09-19T16:11:29.192360Z",
     "iopub.status.idle": "2021-09-19T16:11:29.200971Z",
     "shell.execute_reply": "2021-09-19T16:11:29.199725Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.193285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove duplicated rows\n",
    "train_df.drop(train_df.index[[2587,4755,7311,7315]], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.203784Z",
     "iopub.status.busy": "2021-09-19T16:11:29.203014Z",
     "iopub.status.idle": "2021-09-19T16:11:29.219638Z",
     "shell.execute_reply": "2021-09-19T16:11:29.217946Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.203737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7996"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final check for the total number of unique questions\n",
    "len(train_df.question.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.221965Z",
     "iopub.status.busy": "2021-09-19T16:11:29.221424Z",
     "iopub.status.idle": "2021-09-19T16:11:29.266473Z",
     "shell.execute_reply": "2021-09-19T16:11:29.265287Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.221923Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the validation data using the extract_questions_and_sql function\n",
    "validation_df = extract_questions_and_sql(\"../input/validation-data/dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.269625Z",
     "iopub.status.busy": "2021-09-19T16:11:29.269280Z",
     "iopub.status.idle": "2021-09-19T16:11:29.284662Z",
     "shell.execute_reply": "2021-09-19T16:11:29.282989Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.269595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>sql_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count the number of patients whose diagnoses s...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which patients have seroma complicating a proc...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>give the number of patients diagnosed with mal...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how many patients have been diagnosed with oli...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which patients had cardiopulmonary resuscitati...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  count the number of patients whose diagnoses s...   \n",
       "1  which patients have seroma complicating a proc...   \n",
       "2  give the number of patients diagnosed with mal...   \n",
       "3  how many patients have been diagnosed with oli...   \n",
       "4  which patients had cardiopulmonary resuscitati...   \n",
       "\n",
       "                                           sql_query  \n",
       "0  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "1  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "2  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "3  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "4  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 5 rows\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.287938Z",
     "iopub.status.busy": "2021-09-19T16:11:29.286900Z",
     "iopub.status.idle": "2021-09-19T16:11:29.297031Z",
     "shell.execute_reply": "2021-09-19T16:11:29.295577Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.287889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the total number of rows and columns\n",
    "validation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.300872Z",
     "iopub.status.busy": "2021-09-19T16:11:29.300361Z",
     "iopub.status.idle": "2021-09-19T16:11:29.314189Z",
     "shell.execute_reply": "2021-09-19T16:11:29.312685Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.300841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question     0\n",
       "sql_query    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any missing values\n",
    "validation_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.319587Z",
     "iopub.status.busy": "2021-09-19T16:11:29.318851Z",
     "iopub.status.idle": "2021-09-19T16:11:29.330849Z",
     "shell.execute_reply": "2021-09-19T16:11:29.329594Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.319504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the total number of duplicated rows\n",
    "validation_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.332850Z",
     "iopub.status.busy": "2021-09-19T16:11:29.332338Z",
     "iopub.status.idle": "2021-09-19T16:11:29.341841Z",
     "shell.execute_reply": "2021-09-19T16:11:29.340604Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.332793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the total number of unique questions\n",
    "len(validation_df.question.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.344050Z",
     "iopub.status.busy": "2021-09-19T16:11:29.343378Z",
     "iopub.status.idle": "2021-09-19T16:11:29.352684Z",
     "shell.execute_reply": "2021-09-19T16:11:29.351335Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.344004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the total number of unique SQL queries\n",
    "len(validation_df.sql_query.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.363185Z",
     "iopub.status.busy": "2021-09-19T16:11:29.362886Z",
     "iopub.status.idle": "2021-09-19T16:11:29.516584Z",
     "shell.execute_reply": "2021-09-19T16:11:29.515498Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.363155Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the test data using the extract_questions_and_sql function\n",
    "test_df = extract_questions_and_sql(\"../input/test-data/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.520597Z",
     "iopub.status.busy": "2021-09-19T16:11:29.520124Z",
     "iopub.status.idle": "2021-09-19T16:11:29.533954Z",
     "shell.execute_reply": "2021-09-19T16:11:29.532457Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.520523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>sql_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how many patients were born before the year 2060?</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how many patients had the diagnosis icd9 code ...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>let me know the number of patients who have di...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the total number of patiemts who had c...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>give me the number of patients who have been d...</td>\n",
       "      <td>SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  how many patients were born before the year 2060?   \n",
       "1  how many patients had the diagnosis icd9 code ...   \n",
       "2  let me know the number of patients who have di...   \n",
       "3  what is the total number of patiemts who had c...   \n",
       "4  give me the number of patients who have been d...   \n",
       "\n",
       "                                           sql_query  \n",
       "0  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "1  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "2  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "3  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  \n",
       "4  SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_I...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 5 rows\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.537808Z",
     "iopub.status.busy": "2021-09-19T16:11:29.537075Z",
     "iopub.status.idle": "2021-09-19T16:11:29.548477Z",
     "shell.execute_reply": "2021-09-19T16:11:29.546879Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.537749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the total number of rows and columns\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.551542Z",
     "iopub.status.busy": "2021-09-19T16:11:29.550797Z",
     "iopub.status.idle": "2021-09-19T16:11:29.564981Z",
     "shell.execute_reply": "2021-09-19T16:11:29.563895Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.551486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question     0\n",
       "sql_query    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any missing values\n",
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.567741Z",
     "iopub.status.busy": "2021-09-19T16:11:29.567000Z",
     "iopub.status.idle": "2021-09-19T16:11:29.579984Z",
     "shell.execute_reply": "2021-09-19T16:11:29.578425Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.567697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the total number of duplicated rows\n",
    "test_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.582835Z",
     "iopub.status.busy": "2021-09-19T16:11:29.582093Z",
     "iopub.status.idle": "2021-09-19T16:11:29.592917Z",
     "shell.execute_reply": "2021-09-19T16:11:29.591186Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.582790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the total number of unique questions\n",
    "len(test_df.question.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.595861Z",
     "iopub.status.busy": "2021-09-19T16:11:29.595209Z",
     "iopub.status.idle": "2021-09-19T16:11:29.605660Z",
     "shell.execute_reply": "2021-09-19T16:11:29.604362Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.595818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the total number of unique SQL queries\n",
    "len(test_df.sql_query.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:29.608244Z",
     "iopub.status.busy": "2021-09-19T16:11:29.607467Z",
     "iopub.status.idle": "2021-09-19T16:11:38.633527Z",
     "shell.execute_reply": "2021-09-19T16:11:38.632445Z",
     "shell.execute_reply.started": "2021-09-19T16:11:29.608201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import essential libraries for the modelling section\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5TokenizerFast as T5Tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:38.637257Z",
     "iopub.status.busy": "2021-09-19T16:11:38.636870Z",
     "iopub.status.idle": "2021-09-19T16:11:38.650077Z",
     "shell.execute_reply": "2021-09-19T16:11:38.648375Z",
     "shell.execute_reply.started": "2021-09-19T16:11:38.637228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random seed\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:38.652913Z",
     "iopub.status.busy": "2021-09-19T16:11:38.652222Z",
     "iopub.status.idle": "2021-09-19T16:11:38.659498Z",
     "shell.execute_reply": "2021-09-19T16:11:38.658211Z",
     "shell.execute_reply.started": "2021-09-19T16:11:38.652852Z"
    }
   },
   "outputs": [],
   "source": [
    "modelName = \"t5-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:38.661967Z",
     "iopub.status.busy": "2021-09-19T16:11:38.661172Z",
     "iopub.status.idle": "2021-09-19T16:11:43.004580Z",
     "shell.execute_reply": "2021-09-19T16:11:43.002605Z",
     "shell.execute_reply.started": "2021-09-19T16:11:38.661907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca38560c0494e8592ca24b413e6dde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8b73917ae34ac284c80c9ffa52f3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the T5 tokenizer from the pretained T5 base model \n",
    "tokenizer = T5Tokenizer.from_pretrained(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:43.007577Z",
     "iopub.status.busy": "2021-09-19T16:11:43.006709Z",
     "iopub.status.idle": "2021-09-19T16:11:43.026170Z",
     "shell.execute_reply": "2021-09-19T16:11:43.024471Z",
     "shell.execute_reply.started": "2021-09-19T16:11:43.007531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Class to create a dataset that is extended from PyTorch dataset\n",
    "class MimicSQLDataset(Dataset):\n",
    "    # Create a constructer\n",
    "    def __init__(\n",
    "        self,\n",
    "        # The data as pandas DataFrame\n",
    "        data: pd.DataFrame,\n",
    "        # The tokenizer\n",
    "        tokenizer: T5Tokenizer,\n",
    "        # maximum token length of the source text which is the question \n",
    "        source_max_token_len: int = 256,\n",
    "        # maximum token length of the target text which is the SQL query \n",
    "        target_max_token_len: int = 128\n",
    "    ):\n",
    "        # Store everything\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "        \n",
    "    # The __len__ (length) method\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # The __getitem__ method\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        \n",
    "        # Source encoding - the natural questions\n",
    "        source_encoding = tokenizer(\n",
    "            data_row[\"question\"],\n",
    "            # Set maximum length as the maximum token length of the source text\n",
    "            max_length = self.source_max_token_len,\n",
    "            padding = \"max_length\",\n",
    "            truncation = \"only_first\",\n",
    "            add_special_tokens = True,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = \"pt\"\n",
    "        )\n",
    "        \n",
    "        # Target encoding - the SQL query\n",
    "        target_encoding = tokenizer(\n",
    "            data_row[\"sql_query\"],\n",
    "            # Set maximum length as the maximum token length of the target text\n",
    "            max_length = self.target_max_token_len,\n",
    "            padding = \"max_length\",\n",
    "            truncation = True,\n",
    "            add_special_tokens = True,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = \"pt\"\n",
    "        \n",
    "        )\n",
    "        \n",
    "        # Create the labels\n",
    "        labels = target_encoding[\"input_ids\"]\n",
    "        # Convert the ignored labels to -100 to be excluded from computation\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return dict(\n",
    "            question = data_row[\"question\"],\n",
    "            sql_query = data_row [\"sql_query\"],\n",
    "            input_ids = source_encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask = source_encoding[\"attention_mask\"].flatten(),\n",
    "            labels = labels.flatten()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:43.046354Z",
     "iopub.status.busy": "2021-09-19T16:11:43.045866Z",
     "iopub.status.idle": "2021-09-19T16:11:43.069029Z",
     "shell.execute_reply": "2021-09-19T16:11:43.067588Z",
     "shell.execute_reply.started": "2021-09-19T16:11:43.046297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Class to create a Lightning Data Module\n",
    "class MimicSQLDataModule(pl.LightningDataModule):\n",
    "    # Create a constructer\n",
    "    def __init__(\n",
    "        self,\n",
    "        # The train data as pandas DataFrame\n",
    "        train_df: pd.DataFrame,\n",
    "        # The validation data as pandas DataFrame\n",
    "        validation_df: pd.DataFrame,\n",
    "        # The test data as pandas DataFrame\n",
    "        test_df: pd.DataFrame,\n",
    "        # The tokenizer\n",
    "        tokenizer: T5Tokenizer,\n",
    "        # The batch size\n",
    "        batch_size: int = 16,\n",
    "        # maximum token length of the source text which is the question\n",
    "        source_max_token_len: int = 256,\n",
    "        # maximum token length of the target text which is the SQL query\n",
    "        target_max_token_len: int = 128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Store everything\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.validation_df = validation_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "    \n",
    "    # The setup method\n",
    "    def setup(self):\n",
    "        self.train_dataset = MimicSQLDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_len,\n",
    "            self.target_max_token_len\n",
    "        )\n",
    "        \n",
    "        self.validation_dataset = MimicSQLDataset(\n",
    "            self.validation_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_len,\n",
    "            self.target_max_token_len\n",
    "        )\n",
    "        \n",
    "        self.test_dataset = MimicSQLDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_len,\n",
    "            self.target_max_token_len\n",
    "        )\n",
    "    \n",
    "    # PyTorch data loaders to save memory and boost up the speed.\n",
    "    \n",
    "    # Train data loader to parallelise the process of data loading with automatic batching.\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            num_workers = 4,\n",
    "            shuffle = True,\n",
    "            batch_size = self.batch_size\n",
    "        )\n",
    "    \n",
    "    # Validation data loader to parallelise the process of data loading with automatic batching.\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.validation_dataset,\n",
    "            num_workers = 4,\n",
    "            batch_size = self.batch_size\n",
    "        ) \n",
    "    \n",
    "    # Test data loader to parallelise the process of data loading with automatic batching.\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            num_workers = 4,\n",
    "            batch_size = self.batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:43.093655Z",
     "iopub.status.busy": "2021-09-19T16:11:43.093153Z",
     "iopub.status.idle": "2021-09-19T16:11:43.108089Z",
     "shell.execute_reply": "2021-09-19T16:11:43.103837Z",
     "shell.execute_reply.started": "2021-09-19T16:11:43.093607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 16\n",
    "# Number of epochs\n",
    "NUM_EPOCHS = 14\n",
    "\n",
    "data_module = MimicSQLDataModule(train_df, validation_df, test_df, tokenizer, batch_size = BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:43.127539Z",
     "iopub.status.busy": "2021-09-19T16:11:43.126884Z",
     "iopub.status.idle": "2021-09-19T16:11:43.153350Z",
     "shell.execute_reply": "2021-09-19T16:11:43.151984Z",
     "shell.execute_reply.started": "2021-09-19T16:11:43.127495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Class to creates a PyTorch Lightning Module \n",
    "class MimicSQLModel(pl.LightningModule):\n",
    "    \n",
    "    # Create a constructer\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(modelName, return_dict = True)\n",
    "    \n",
    "    # The forward method \n",
    "    def forward(self, input_ids, attention_mask, labels = None):\n",
    "        output = self.model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            labels = labels\n",
    "        )\n",
    "        \n",
    "        return output.loss, output.logits\n",
    "    \n",
    "    # The trainig step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar = True, logger = True)\n",
    "        return loss \n",
    "    \n",
    "    # The validation step\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar = True, logger = True)\n",
    "        return loss \n",
    "    \n",
    "    # the test step\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar = True, logger = True)\n",
    "        return loss \n",
    "    \n",
    "    # The optomizer and learning rate\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr = 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:11:43.179797Z",
     "iopub.status.busy": "2021-09-19T16:11:43.179129Z",
     "iopub.status.idle": "2021-09-19T16:12:24.005312Z",
     "shell.execute_reply": "2021-09-19T16:12:24.004207Z",
     "shell.execute_reply.started": "2021-09-19T16:11:43.179752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24691e604cbd44a580a0e73150c171ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab11fda42b4d4905aca3c5cdc3ebdeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the MimicSQLModel() as the model\n",
    "model = MimicSQLModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:12:24.007448Z",
     "iopub.status.busy": "2021-09-19T16:12:24.006980Z",
     "iopub.status.idle": "2021-09-19T16:12:24.019765Z",
     "shell.execute_reply": "2021-09-19T16:12:24.018615Z",
     "shell.execute_reply.started": "2021-09-19T16:12:24.007405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a checkpoint callback  \n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath = \"checkpoints\",\n",
    "    filename = \"best-checkpoint\",\n",
    "    save_top_k = 1,\n",
    "    verbose = True,\n",
    "    monitor = \"val_loss\",\n",
    "    mode = \"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:12:24.022100Z",
     "iopub.status.busy": "2021-09-19T16:12:24.021603Z",
     "iopub.status.idle": "2021-09-19T16:12:24.083821Z",
     "shell.execute_reply": "2021-09-19T16:12:24.082573Z",
     "shell.execute_reply.started": "2021-09-19T16:12:24.022056Z"
    }
   },
   "outputs": [],
   "source": [
    "# PyTorch Lightning trainer for training automation\n",
    "trainer = pl.Trainer(\n",
    "    checkpoint_callback = checkpoint_callback,\n",
    "    max_epochs = NUM_EPOCHS,\n",
    "    gpus = 1,\n",
    "    progress_bar_refresh_rate = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T16:12:24.086774Z",
     "iopub.status.busy": "2021-09-19T16:12:24.085888Z",
     "iopub.status.idle": "2021-09-19T17:47:56.524948Z",
     "shell.execute_reply": "2021-09-19T17:47:56.523573Z",
     "shell.execute_reply.started": "2021-09-19T16:12:24.086722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699e85413c13458ebe4117a90ac8c37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91f661d07414548923481b5383a39f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T17:47:56.527774Z",
     "iopub.status.busy": "2021-09-19T17:47:56.527293Z",
     "iopub.status.idle": "2021-09-19T17:47:57.154689Z",
     "shell.execute_reply": "2021-09-19T17:47:57.153389Z",
     "shell.execute_reply.started": "2021-09-19T17:47:56.527725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import essential libraries for the evaluation section\n",
    "\n",
    "from random import randrange\n",
    "from sklearn import metrics\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T17:47:57.156804Z",
     "iopub.status.busy": "2021-09-19T17:47:57.156341Z",
     "iopub.status.idle": "2021-09-19T17:47:57.176111Z",
     "shell.execute_reply": "2021-09-19T17:47:57.174891Z",
     "shell.execute_reply.started": "2021-09-19T17:47:57.156760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MimicSQLModel(\n",
       "  (model): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(32128, 768)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch the model out of the training mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T17:47:57.178876Z",
     "iopub.status.busy": "2021-09-19T17:47:57.178093Z",
     "iopub.status.idle": "2021-09-19T17:47:57.190827Z",
     "shell.execute_reply": "2021-09-19T17:47:57.189627Z",
     "shell.execute_reply.started": "2021-09-19T17:47:57.178832Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function that takes a question and predicts the corresponding SQl query\n",
    "def sql_generator(question):\n",
    "    source_encoding = tokenizer(\n",
    "        question[\"question\"],\n",
    "        max_length = 256,\n",
    "        padding = \"max_length\",\n",
    "        truncation = \"only_first\",\n",
    "        return_attention_mask = True,\n",
    "        add_special_tokens  = True,\n",
    "        return_tensors = \"pt\"\n",
    "    )\n",
    "    \n",
    "    ids_generated = model.model.generate(\n",
    "        # The input ids of the source encoding \n",
    "        input_ids=source_encoding[\"input_ids\"],\n",
    "        # The attention mask of the source encoding\n",
    "        attention_mask=source_encoding[\"attention_mask\"],\n",
    "        # greedy search\n",
    "        num_beams=1,\n",
    "        max_length=180,\n",
    "        repetition_penalty=2.5,\n",
    "        early_stopping=True,\n",
    "        use_cache=True)\n",
    "    \n",
    "    predictions = [\n",
    "        tokenizer.decode(id_generated, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for id_generated in ids_generated\n",
    "    ]\n",
    "    \n",
    "    return \"\".join(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T17:47:57.207916Z",
     "iopub.status.busy": "2021-09-19T17:47:57.207281Z",
     "iopub.status.idle": "2021-09-19T17:48:42.810408Z",
     "shell.execute_reply": "2021-09-19T17:48:42.809224Z",
     "shell.execute_reply.started": "2021-09-19T17:47:57.207869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provide me the number of patients who were hospitalized for more than a day and were less than 89 years of age.\n",
      "\n",
      "Actual SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"AGE\" < \"89\" AND DEMOGRAPHIC.\"DAYS_STAY\" > \"1\"\n",
      "Predicted SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"AGE\"  \"89\" AND DEMOGRAPHIC.\"DAYS_STAY\" > \"1\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "What is the number of patients admitted before year 2139 whose procedure long title is other closed [endoscopic] biopsy of biliary duct or sphincter of oddi?\n",
      "\n",
      "Actual SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC INNER JOIN PROCEDURES on DEMOGRAPHIC.HADM_ID = PROCEDURES.HADM_ID WHERE DEMOGRAPHIC.\"ADMITYEAR\" < \"2139\" AND PROCEDURES.\"LONG_TITLE\" = \"Other closed [endoscopic] biopsy of biliary duct or sphincter of Oddi\"\n",
      "Predicted SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC INNER JOIN PROCEDURES on DEMOGRAPHIC.HADM_ID = PROCEDURES.HADM_ID WHERE DEMOGRAPHIC.\"ADMITYEAR\"  \"2139\" AND PROCEDURES.\"LONG_TITLE\" = \"Other closed [endoscopic] biopsy of biliary duct or sphincter'\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "how many patients whose language is spanish are aged below 83 years?\n",
      "\n",
      "Actual SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"LANGUAGE\" = \"SPAN\" AND DEMOGRAPHIC.\"AGE\" < \"83\"\n",
      "Predicted SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"LANGUAGE\" = \"SPAN\" AND DEMOGRAPHIC.\"AGE\"  \"83\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Calculate the number of patients treated with drug hydx25 who died in or before the year 2186.\n",
      "\n",
      "Actual SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC INNER JOIN PRESCRIPTIONS on DEMOGRAPHIC.HADM_ID = PRESCRIPTIONS.HADM_ID WHERE DEMOGRAPHIC.\"DOD_YEAR\" <= \"2186.0\" AND PRESCRIPTIONS.\"FORMULARY_DRUG_CD\" = \"HYDX25\"\n",
      "Predicted SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC INNER JOIN PRESCRIPTIONS on DEMOGRAPHIC.HADM_ID = PRESCRIPTIONS.HADM_ID WHERE DEMOGRAPHIC.\"DOD_YEAR\" = \"2186.0\" AND PRESCRIPTIONS.\"FORMULARY_DRUG_CD\" = \"HYDX25\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "what is the admission time and diagnoses short title of subject name thomas nazario?\n",
      "\n",
      "Actual SQL query: SELECT DEMOGRAPHIC.\"ADMITTIME\",DIAGNOSES.\"SHORT_TITLE\" FROM DEMOGRAPHIC INNER JOIN DIAGNOSES on DEMOGRAPHIC.HADM_ID = DIAGNOSES.HADM_ID WHERE DEMOGRAPHIC.\"NAME\" = \"Thomas Nazario\"\n",
      "Predicted SQL query: SELECT DEMOGRAPHIC.\"ADMITTIME\",DIAGNOSES.\"SHORT_TITLE\" FROM DEMOGRAPHIC INNER JOIN DIAGNOSES on DEMOGRAPHIC.HADM_ID = DIAGNOSES.HADM_ID WHERE DEMOGRAPHIC.\"NAME\" = \"Thomas Nazario\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate randomly 5 questions along with their corresponding actual and predicted SQL queries.\n",
    "for numbers in range(5):\n",
    "    nums = []\n",
    "    nums.append(randrange(0, 1000))\n",
    "    for num in nums:\n",
    "        random_question = validation_df.iloc[num]\n",
    "        print(random_question[\"question\"])\n",
    "        print(\"\\nActual SQL query: %s\" % random_question[\"sql_query\"])\n",
    "        print(\"Predicted SQL query: %s\" % sql_generator(random_question))\n",
    "        print(\"--------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T17:48:42.821384Z",
     "iopub.status.busy": "2021-09-19T17:48:42.820693Z",
     "iopub.status.idle": "2021-09-19T20:24:40.389762Z",
     "shell.execute_reply": "2021-09-19T20:24:40.388647Z",
     "shell.execute_reply.started": "2021-09-19T17:48:42.821289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a list of correct SQL queries and a list of predicted SQL queries.\n",
    "correct_query = []\n",
    "predicted_query = []\n",
    "for i in range(1000):\n",
    "    question = validation_df.iloc[i]\n",
    "    correct_query.append(question[\"sql_query\"])\n",
    "    predicted_query.append(sql_generator(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T20:24:40.399743Z",
     "iopub.status.busy": "2021-09-19T20:24:40.398779Z",
     "iopub.status.idle": "2021-09-19T20:24:40.430045Z",
     "shell.execute_reply": "2021-09-19T20:24:40.428365Z",
     "shell.execute_reply.started": "2021-09-19T20:24:40.399670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.457"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exact match accuracy\n",
    "metrics.accuracy_score(correct_query, predicted_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T20:32:00.076244Z",
     "iopub.status.busy": "2021-09-19T20:32:00.075901Z",
     "iopub.status.idle": "2021-09-19T20:32:00.087165Z",
     "shell.execute_reply": "2021-09-19T20:32:00.085691Z",
     "shell.execute_reply.started": "2021-09-19T20:32:00.076213Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply fuzz.ratio and make a list of fuzz ratio scores\n",
    "results = []\n",
    "for (correct,predicted) in zip(correct_query, predicted_query):\n",
    "    results.append(fuzz.ratio(correct,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T20:32:15.816674Z",
     "iopub.status.busy": "2021-09-19T20:32:15.816151Z",
     "iopub.status.idle": "2021-09-19T20:32:15.825131Z",
     "shell.execute_reply": "2021-09-19T20:32:15.823760Z",
     "shell.execute_reply.started": "2021-09-19T20:32:15.816633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.952"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average score of fuzz ratio\n",
    "sum(results)/len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T20:33:33.880421Z",
     "iopub.status.busy": "2021-09-19T20:33:33.880009Z",
     "iopub.status.idle": "2021-09-19T20:34:11.721914Z",
     "shell.execute_reply": "2021-09-19T20:34:11.720476Z",
     "shell.execute_reply.started": "2021-09-19T20:33:33.880390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the diagnosis of Tracy Farmer?\n",
      "\n",
      "Actual SQL query: SELECT DIAGNOSES.\"SHORT_TITLE\" FROM DEMOGRAPHIC INNER JOIN DIAGNOSES on DEMOGRAPHIC.HADM_ID = DIAGNOSES.HADM_ID WHERE DEMOGRAPHIC.\"NAME\" = \"Tracy Farmer\"\n",
      "Predicted SQL query: SELECT DIAGNOSES.\"LONG_TITLE\" FROM DEMOGRAPHIC INNER JOIN DIAGNOSES on DEMOGRAPHIC.HADM_ID = DIAGNOSES.HADM_ID WHERE DEMOGRAPHIC.\"NAME\" = \"Tracy Farmer\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "provide me the procedure icd9 code of patient with patient id 1875.\n",
      "\n",
      "Actual SQL query: SELECT PROCEDURES.\"ICD9_CODE\" FROM PROCEDURES WHERE PROCEDURES.\"SUBJECT_ID\" = \"1875\"\n",
      "Predicted SQL query: SELECT PROCEDURES.\"ICD9_CODE\" FROM PROCEDURES WHERE PROCEDURES.\"SUBJECT_ID\" = \"1875\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Is the subject id 74032 married, find his religion ?\n",
      "\n",
      "Actual SQL query: SELECT DEMOGRAPHIC.\"MARITAL_STATUS\",DEMOGRAPHIC.\"RELIGION\" FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"SUBJECT_ID\" = \"74032\"\n",
      "Predicted SQL query: SELECT DEMOGRAPHIC.\"MARITAL_STATUS\",DEMOGRAPHIC.\"RELIGION\" FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"SUBJECT_ID\" = \"74032\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "find the number of patients whose drug route is dialys and age under 83 years.\n",
      "\n",
      "Actual SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC INNER JOIN PRESCRIPTIONS on DEMOGRAPHIC.HADM_ID = PRESCRIPTIONS.HADM_ID WHERE DEMOGRAPHIC.\"AGE\" < \"83\" AND PRESCRIPTIONS.\"ROUTE\" = \"DIALYS\"\n",
      "Predicted SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC INNER JOIN PRESCRIPTIONS on DEMOGRAPHIC.HADM_ID = PRESCRIPTIONS.HADM_ID WHERE DEMOGRAPHIC.\"AGE\"  \"83\" AND PRESCRIPTIONS.\"ROUTE\" = \"DIALYS\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "what is the number of patients whose hospital stay is above 16 days and with drug sw?\n",
      "\n",
      "Actual SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC INNER JOIN PRESCRIPTIONS on DEMOGRAPHIC.HADM_ID = PRESCRIPTIONS.HADM_ID WHERE DEMOGRAPHIC.\"DAYS_STAY\" > \"16\" AND PRESCRIPTIONS.\"DRUG\" = \"SW\"\n",
      "Predicted SQL query: SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC INNER JOIN PRESCRIPTIONS on DEMOGRAPHIC.HADM_ID = PRESCRIPTIONS.HADM_ID WHERE DEMOGRAPHIC.\"DAYS_STAY\" > \"16\" AND PRESCRIPTIONS.\"DRUG\" = \"SW\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate randomly 5 questions along with their corresponding actual and predicted SQL queries.\n",
    "for numbers in range(5):\n",
    "    nums = []\n",
    "    nums.append(randrange(0, 1000))\n",
    "    for num in nums:\n",
    "        random_question = test_df.iloc[num]\n",
    "        print(random_question[\"question\"])\n",
    "        print(\"\\nActual SQL query: %s\" % random_question[\"sql_query\"])\n",
    "        print(\"Predicted SQL query: %s\" % sql_generator(random_question))\n",
    "        print(\"--------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T20:34:26.371581Z",
     "iopub.status.busy": "2021-09-19T20:34:26.371181Z",
     "iopub.status.idle": "2021-09-19T22:47:00.682568Z",
     "shell.execute_reply": "2021-09-19T22:47:00.681335Z",
     "shell.execute_reply.started": "2021-09-19T20:34:26.371515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a list of correct SQL queries and a list of predicted SQL queries.\n",
    "correct_query = []\n",
    "predicted_query = []\n",
    "for i in range(1000):\n",
    "    question = test_df.iloc[i]\n",
    "    correct_query.append(question[\"sql_query\"])\n",
    "    predicted_query.append(sql_generator(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T22:52:24.133184Z",
     "iopub.status.busy": "2021-09-19T22:52:24.132804Z",
     "iopub.status.idle": "2021-09-19T22:52:24.150127Z",
     "shell.execute_reply": "2021-09-19T22:52:24.148404Z",
     "shell.execute_reply.started": "2021-09-19T22:52:24.133156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.593"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exact match accuracy\n",
    "metrics.accuracy_score(correct_query, predicted_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T22:54:18.274674Z",
     "iopub.status.busy": "2021-09-19T22:54:18.274285Z",
     "iopub.status.idle": "2021-09-19T22:54:18.284600Z",
     "shell.execute_reply": "2021-09-19T22:54:18.282863Z",
     "shell.execute_reply.started": "2021-09-19T22:54:18.274642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply fuzz.ratio and make a list of fuzz ratio scores\n",
    "results = []\n",
    "for (correct,predicted) in zip(correct_query, predicted_query):\n",
    "    results.append(fuzz.ratio(correct,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T22:54:29.359679Z",
     "iopub.status.busy": "2021-09-19T22:54:29.359323Z",
     "iopub.status.idle": "2021-09-19T22:54:29.368263Z",
     "shell.execute_reply": "2021-09-19T22:54:29.366757Z",
     "shell.execute_reply.started": "2021-09-19T22:54:29.359648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.506"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy using fuzz.ratio\n",
    "sum(results)/len(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
